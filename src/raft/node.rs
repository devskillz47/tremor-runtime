// Copyright 2022, The Tremor Team
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The entirety of a cluster node as a struct
use crate::{
    errors::Result,
    raft::{
        api, app,
        network::{raft, Raft as TarPCRaftService},
        store::Store,
        ClusterError, ClusterResult, Network, NodeId,
    },
    system::{Runtime, ShutdownMode, WorldConfig},
};
use async_std::{
    channel::{bounded, Sender},
    net::ToSocketAddrs,
    task::{self, JoinHandle},
};
use futures::{future, prelude::*};
use openraft::{Config, Raft};
use std::{
    collections::BTreeSet,
    path::{Path, PathBuf},
    sync::Arc,
    time::Duration,
};
use tarpc::{
    server::{self, Channel},
    tokio_serde::formats::Json,
};

use super::store::{TremorRequest, TremorResponse};

#[derive(Clone, Debug)]
pub struct ClusterNodeKillSwitch {
    sender: Sender<ShutdownMode>,
}

impl ClusterNodeKillSwitch {
    /// Stop the running node with the given `mode`
    /// # Errors
    /// if the node is already stopped or failed to be stopped
    pub fn stop(&self, mode: ShutdownMode) -> ClusterResult<()> {
        self.sender
            .try_send(mode)
            .map_err(|_| ClusterError::from("Error stopping cluster node"))
    }
}

pub struct Running {
    node: Node,
    server_state: Arc<app::Tremor>,
    kill_switch_tx: Sender<ShutdownMode>,
    run_handle: JoinHandle<ClusterResult<()>>,
}

impl Running {
    #[must_use]
    pub fn node_data(&self) -> (NodeId, Addr) {
        (self.server_state.id, self.server_state.addr.clone())
    }

    #[must_use]
    pub fn node(&self) -> &Node {
        &self.node
    }

    async fn start(
        node: Node,
        raft: Raft<TremorRequest, TremorResponse, Network, Store>,
        server_state: Arc<app::Tremor>,
        runtime: Runtime,
        runtime_handle: JoinHandle<Result<()>>,
    ) -> ClusterResult<Self> {
        let (kill_switch_tx, kill_switch_rx) = bounded(1);

        let tcp_server_state = server_state.clone();
        let mut listener =
            tarpc::serde_transport::tcp::listen(&server_state.addr.rpc(), Json::default).await?;
        listener.config_mut().max_frame_length(usize::MAX);

        let http_api_addr = server_state.addr.api().to_string();
        let mut http_api_server = tide::Server::with_state(server_state.clone());
        api::install_rest_endpoints(&mut http_api_server);
        let run_handle = task::spawn(async move {
            let mut tcp_future = Box::pin(
                listener
                    // Ignore accept errors.
                    .filter_map(|r| future::ready(r.ok()))
                    .map(server::BaseChannel::with_defaults)
                    // Limit channels to 1 per IP.
                    // FIXME .max_channels_per_key(1, |t| t.transport().peer_addr().unwrap().ip())
                    // serve is generated by the service attribute. It takes as input any type implementing
                    // the generated World trait.
                    .map(|channel| {
                        let server = raft::Server::new(tcp_server_state.clone());
                        channel.execute(server.serve())
                    })
                    // Max 10 channels.
                    .buffer_unordered(10)
                    .for_each(|_| async {})
                    .fuse(),
            );
            let mut http_future = Box::pin(http_api_server.listen(http_api_addr).fuse());
            let mut runtime_future = Box::pin(runtime_handle.fuse());
            let mut kill_switch_future = Box::pin(kill_switch_rx.recv().fuse());
            futures::select! {
                _ = tcp_future => {
                    warn!("TCP cluster API shutdown.");
                    raft.shutdown().await.map_err(|_| ClusterError::from("Error shutting down local raft node"))?;
                    runtime.stop(ShutdownMode::Graceful).await?;
                    runtime_future.await?;
                }
                http_res = http_future => {
                    if let Err(e) = http_res {
                        error!("HTTP cluster API failed: {e}");
                    }
                    raft.shutdown().await.map_err(|_| ClusterError::from("Error shutting down local raft node"))?;
                    runtime.stop(ShutdownMode::Graceful).await?;
                    runtime_future.await?;

                }
                runtime_res = runtime_future => {
                    if let Err(e) = runtime_res {
                        error!("Local runtime failed: {e}");
                    }
                    // runtime is already down, we only need to stop local raft
                    raft.shutdown().await.map_err(|_| ClusterError::from("Error shutting down local raft node"))?;
                }
                shutdown_mode = kill_switch_future => {
                    let shutdown_mode = shutdown_mode.unwrap_or(ShutdownMode::Forceful);
                    info!("Tremor cluster node stopping in {shutdown_mode:?} mode");
                    // tcp and http api stopped listening as we don't poll them no more
                    // FIXME: something here is hanging infinitely
                    raft.shutdown().await.map_err(|_| ClusterError::from("Error shutting down local raft node"))?;
                    info!("Raft engine did stop.");
                    info!("Stopping the Tremor runtime...");
                    runtime.stop(shutdown_mode).await?;
                    runtime_future.await?;
                    info!("Tremor runtime stopped.");
                }
            }
            info!("Tremor cluster node stopped");
            Ok::<(), ClusterError>(())
        });

        Ok(Self {
            node,
            server_state,
            kill_switch_tx,
            run_handle,
        })
    }

    /// get a kill-switch
    #[must_use]
    pub fn kill_switch(&self) -> ClusterNodeKillSwitch {
        ClusterNodeKillSwitch {
            sender: self.kill_switch_tx.clone(),
        }
    }

    /// block until the cluster node is done noodling
    ///
    /// # Errors
    /// if the node failed to run
    pub async fn join(self) -> ClusterResult<()> {
        self.run_handle.await
    }
}

/// internal struct carrying all data to start a cluster node
/// and keeps all the state for an ordered clean shutdown
#[derive(Clone, Debug)]
pub struct Node {
    db_dir: PathBuf,
    raft_config: Arc<Config>,
}

#[derive(Clone, Debug, Serialize, Deserialize, Hash, Eq, PartialEq)]
pub struct Addr {
    /// Address for API access (from outside of the cluster)
    api: String,
    /// Address for RPC access (inter-node)
    rpc: String,
}

impl std::fmt::Display for Addr {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("Addr")
            .field("api", &self.api)
            .field("rpc", &self.rpc)
            .finish()
    }
}

impl Addr {
    /// constructor
    pub fn new(api: impl Into<String>, rpc: impl Into<String>) -> Self {
        Self {
            api: api.into(),
            rpc: rpc.into(),
        }
    }

    /// get the api addr
    #[must_use]
    pub fn api(&self) -> &str {
        &self.api
    }

    /// get the rpc addr
    #[must_use]
    pub fn rpc(&self) -> &str {
        &self.rpc
    }
}

impl Node {
    pub fn new(db_dir: impl AsRef<Path>, raft_config: Config) -> Self {
        Self {
            db_dir: PathBuf::from(db_dir.as_ref()),
            raft_config: Arc::new(raft_config),
        }
    }
    /// Load the latest state from `db_dir`
    /// and start the cluster with it
    ///
    /// # Errors
    /// if the store does not exist, is not properly initialized
    pub async fn load_from_store(
        db_dir: impl AsRef<Path> + ToSocketAddrs,
        raft_config: Config,
    ) -> ClusterResult<Running> {
        let world_config = WorldConfig::default(); // TODO: make configurable
        let (runtime, runtime_handle) = Runtime::start(world_config).await?;

        let store: Arc<Store> = Store::load(&db_dir, runtime.clone()).await?;
        // ensure we have working node data
        let (node_id, addr) = store.get_self()?;
        let node = Self::new(db_dir, raft_config.clone());

        let network = Network::new(store.clone());
        let raft = Raft::new(node_id, node.raft_config.clone(), network, store.clone());
        let server_state = Arc::new(app::Tremor {
            id: node_id,
            addr,
            raft: raft.clone(),
            store,
        });
        Running::start(node, raft, server_state, runtime, runtime_handle).await
    }

    /// Just start the cluster node and let it do whatever it does
    /// # Errors
    /// when the node can't be started
    pub async fn try_join(
        &mut self,
        addr: Addr,
        endpoints: Vec<String>,
        promote_to_voter: bool,
    ) -> ClusterResult<Running> {
        if endpoints.is_empty() {
            return Err(ClusterError::Other(
                "No join endpoints provided".to_string(),
            ));
        }

        // for now we infinitely try to join until it succeeds
        let mut join_wait = Duration::from_secs(2);
        let (client, node_id) = 'outer: loop {
            for endpoint in &endpoints {
                info!("Trying to join existing cluster via {endpoint}...");
                let client = api::client::Tremor::new(endpoint)?;
                // TODO: leader will start replication stream to this node and fail, until we start our machinery
                let node_id = match client.add_node(&addr).await {
                    Ok(node_id) => node_id,
                    Err(e) => {
                        // TODO: ensure we don't error here, when we are already learner
                        warn!("Error connecting to {endpoint}: {e}");
                        continue;
                    }
                };
                break 'outer (client, node_id);
            }
            // exponential backoff
            join_wait *= 2;
            info!(
                "Waiting for {}s before retrying to join...",
                join_wait.as_secs()
            );
            task::sleep(join_wait).await;
        };

        let world_config = WorldConfig::default(); // TODO: make configurable
        let (runtime, runtime_handle) = Runtime::start(world_config).await?;
        let store = Store::bootstrap(node_id, &addr, &self.db_dir, runtime.clone()).await?;
        let network = Network::new(store.clone());
        let raft = Raft::new(node_id, self.raft_config.clone(), network, store.clone());

        let server_state = Arc::new(app::Tremor {
            id: node_id,
            addr,
            raft: raft.clone(),
            store,
        });
        let running =
            Running::start(self.clone(), raft, server_state, runtime, runtime_handle).await?;

        // only when the node is started (listens for HTTP, TCP etc)
        // we can add it as learner and optionally promote it to a voter

        info!("Adding Node {node_id} as Learner...");
        let res = client.add_learner(node_id).await?;
        info!("Node {node_id} successully added as learner");
        if let Some(log_id) = res {
            info!("Learner {node_id} has applied the log up to {log_id}.");
        }

        if promote_to_voter {
            info!("Promoting Node {node_id} to Voter...");
            client.promote_voter(&node_id).await?;
            // FIXME: wait for the node to be a voter
            info!("Node {node_id} became Voter.");
        }
        Ok(running)
    }

    /// Bootstrap and start this cluster node as a single node cluster
    /// of which it immediately becomes the leader.
    /// # Errors
    /// if bootstrapping a a leader fails
    pub async fn bootstrap_as_single_node_cluster(&mut self, addr: Addr) -> ClusterResult<Running> {
        let world_config = WorldConfig::default(); // TODO: make configurable
        let (runtime, runtime_handle) = Runtime::start(world_config).await?;
        let node_id = NodeId::default();
        let store = Store::bootstrap(node_id, &addr, &self.db_dir, runtime.clone()).await?;
        let network = Network::new(store.clone());

        let raft = Raft::new(node_id, self.raft_config.clone(), network, store.clone());

        let mut nodes = BTreeSet::new();
        nodes.insert(node_id);
        // this is the crucial bootstrapping step
        raft.initialize(nodes).await?;
        // lets make ourselves known to the cluster state as first operation, so new joiners will see us as well
        // this is critical
        // FIXME: debug_assert that node_id remains 0
        match raft
            .client_write(TremorRequest::AddNode { addr: addr.clone() })
            .await
        {
            Ok(r) => {
                let assigned_node_id = r
                    .data
                    .value
                    .ok_or_else(|| {
                        ClusterError::Other("Invalid Response from raft for AddNode".to_string())
                    })?
                    .parse::<NodeId>()
                    .map_err(|e| {
                        ClusterError::Other(format!("Invalid node_id returned from AddNode: {e}"))
                    })?;
                debug_assert_eq!(node_id, assigned_node_id, "Adding initial leader resulted in a differing node_id: {assigned_node_id}, expected: {node_id}");
                let server_state = Arc::new(app::Tremor {
                    id: node_id,
                    addr,
                    raft: raft.clone(),
                    store,
                });
                Running::start(self.clone(), raft, server_state, runtime, runtime_handle).await
            }
            Err(e) => Err(ClusterError::Other(format!(
                "Error adding myself to the bootstrapped cluster: {e}"
            ))),
        }
    }
}
